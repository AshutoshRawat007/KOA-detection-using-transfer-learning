{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a82ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.sys.path\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.applications import  ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras import backend as K\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfb06ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df lenght:  5839   valid_df length:  826\n",
      "The number of classes in the dataset is:  5\n",
      "            CLASS               IMAGE COUNT \n",
      "           Doubtful                1046     \n",
      "           Healthy                 2286     \n",
      "           Minimal                 1516     \n",
      "           Moderate                 802     \n",
      "            Severe                  189     \n",
      "Healthy  has the most images=  2286   Severe  has the least images=  189\n",
      "average height=  224  average width=  224 aspect ratio=  1.0\n"
     ]
    }
   ],
   "source": [
    "train_path=r'C:\\Users\\deepa\\OneDrive\\Desktop\\major2\\Knee_data_Clahe\\train'\n",
    "valid_path=r'C:\\Users\\deepa\\OneDrive\\Desktop\\major2\\Knee_data_Clahe\\val'\n",
    "list_of_classes=['Healthy','Doubtful','Minimal','Moderate', 'Severe']\n",
    "for d in [train_path,  valid_path]:\n",
    "    filepaths = []\n",
    "    labels=[]\n",
    "    classlist=os.listdir(d)\n",
    "    for klass in classlist:\n",
    "        intklass=int(klass)\n",
    "        label=list_of_classes[intklass]\n",
    "        classpath=os.path.join(d, klass)\n",
    "        flist=os.listdir(classpath)\n",
    "        for f in flist:\n",
    "            fpath=os.path.join(classpath,f)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(label)\n",
    "    Fseries=pd.Series(filepaths, name='filepaths')\n",
    "    Lseries=pd.Series(labels, name='labels')\n",
    "    pdf=pd.concat([Fseries, Lseries], axis=1)\n",
    "    if d == valid_path:\n",
    "        valid_df=pdf\n",
    "    else:\n",
    "        train_df=pdf\n",
    "print('train_df lenght: ', len(train_df), '  valid_df length: ', len(valid_df))\n",
    "# get the number of classes and the images count for each class in train_df\n",
    "classes=sorted(list(train_df['labels'].unique()))\n",
    "class_count = len(classes)\n",
    "print('The number of classes in the dataset is: ', class_count)\n",
    "groups=train_df.groupby('labels')\n",
    "print('{0:^30s} {1:^13s}'.format('CLASS', 'IMAGE COUNT'))\n",
    "countlist=[]\n",
    "classlist=[]\n",
    "for label in sorted(list(train_df['labels'].unique())):\n",
    "    group=groups.get_group(label)\n",
    "    countlist.append(len(group))\n",
    "    classlist.append(label)\n",
    "    print('{0:^30s} {1:^13s}'.format(label, str(len(group))))\n",
    "\n",
    "# get the classes with the minimum and maximum number of train images\n",
    "max_value=np.max(countlist)\n",
    "max_index=countlist.index(max_value)\n",
    "max_class=classlist[max_index]\n",
    "min_value=np.min(countlist)\n",
    "min_index=countlist.index(min_value)\n",
    "min_class=classlist[min_index]\n",
    "print(max_class, ' has the most images= ',max_value, ' ', min_class, ' has the least images= ', min_value)\n",
    "# lets get the average height and width of a sample of the train images\n",
    "ht=0\n",
    "wt=0\n",
    "# select 100 random samples of train_df\n",
    "train_df_sample=train_df.sample(n=100, random_state=123,axis=0)\n",
    "for i in range (len(train_df_sample)):\n",
    "    fpath=train_df_sample['filepaths'].iloc[i]\n",
    "    img=plt.imread(fpath)\n",
    "    shape=img.shape\n",
    "    ht += shape[0]\n",
    "    wt += shape[1]\n",
    "print('average height= ', ht//100, ' average width= ', wt//100, 'aspect ratio= ', ht/wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fabdaed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy 2286\n",
      "Minimal 1516\n",
      "Severe 189\n"
     ]
    }
   ],
   "source": [
    "drop_classes = ['Doubtful','Moderate']\n",
    "\n",
    "train_df = train_df[~train_df['labels'].isin(drop_classes)]\n",
    "valid_df = valid_df[~valid_df['labels'].isin(drop_classes)]\n",
    "\n",
    "\n",
    "# Update the list of classes\n",
    "list_of_classes = [c for c in list_of_classes if c not in drop_classes]\n",
    "\n",
    "# Re-calculate the total classes\n",
    "class_count = len(list_of_classes)\n",
    "\n",
    "# Re-count the images per class\n",
    "groups = train_df.groupby('labels')\n",
    "for label in list_of_classes:\n",
    "    group = groups.get_group(label)\n",
    "    print(label, len(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c030727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after trimming, the maximum samples in any class is now  500  and the minimum samples in any class is  189\n"
     ]
    }
   ],
   "source": [
    "def trim(df, max_samples, min_samples, column):\n",
    "    df=df.copy()\n",
    "    groups=df.groupby(column)\n",
    "    trimmed_df = pd.DataFrame(columns = df.columns)\n",
    "    groups=df.groupby(column)\n",
    "    for label in df[column].unique():\n",
    "        group=groups.get_group(label)\n",
    "        count=len(group)\n",
    "        if count > max_samples:\n",
    "            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)\n",
    "            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "        else:\n",
    "            if count>=min_samples:\n",
    "                sampled_group=group\n",
    "                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "    print('after trimming, the maximum samples in any class is now ',max_samples, ' and the minimum samples in any class is ', min_samples)\n",
    "    return trimmed_df\n",
    "\n",
    "max_samples=500 # since each class has more than 200 images all classes will be trimmed to have 200 images per class\n",
    "min_samples=189\n",
    "column='labels'\n",
    "train_df= trim(train_df, max_samples, min_samples, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43c71508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial length of dataframe is  2189\n",
      "Found 189 validated image filenames.     for class             Severe             creating  311  augmented images \n",
      "Total Augmented images created=  311\n",
      "Length of augmented dataframe is now  2500\n"
     ]
    }
   ],
   "source": [
    "def balance(df, n, working_dir, img_size):\n",
    "    df=df.copy()\n",
    "    print('Initial length of dataframe is ', len(df))\n",
    "    aug_dir=os.path.join(working_dir, 'aug')# directory to store augmented images\n",
    "    if os.path.isdir(aug_dir):# start with an empty directory\n",
    "        shutil.rmtree(aug_dir)\n",
    "    os.mkdir(aug_dir)\n",
    "    for label in df['labels'].unique():\n",
    "        dir_path=os.path.join(aug_dir,label)\n",
    "        os.mkdir(dir_path) # make class directories within aug directory\n",
    "    # create and store the augmented images\n",
    "    total=0\n",
    "    gen=ImageDataGenerator(horizontal_flip=True,  rotation_range=20, width_shift_range=.2,\n",
    "                                  height_shift_range=.2, zoom_range=.2)\n",
    "    groups=df.groupby('labels') # group by class\n",
    "    for label in df['labels'].unique():  # for every class\n",
    "        group=groups.get_group(label)  # a dataframe holding only rows with the specified label\n",
    "        sample_count=len(group)   # determine how many samples there are in this class\n",
    "        if sample_count< n: # if the class has less than target number of images\n",
    "            aug_img_count=0\n",
    "            delta=n - sample_count  # number of augmented images to create\n",
    "            target_dir=os.path.join(aug_dir, label)  # define where to write the images\n",
    "            msg='{0:40s} for class {1:^30s} creating {2:^5s} augmented images'.format(' ', label, str(delta))\n",
    "            print(msg, '\\r', end='') # prints over on the same line\n",
    "            aug_gen=gen.flow_from_dataframe( group,  x_col='filepaths', y_col=None, target_size=img_size,\n",
    "                                            class_mode=None, batch_size=1, shuffle=False,\n",
    "                                            save_to_dir=target_dir, save_prefix='aug-', color_mode='rgb',\n",
    "                                            save_format='jpg')\n",
    "            while aug_img_count<delta:\n",
    "                images=next(aug_gen)\n",
    "                aug_img_count += len(images)\n",
    "            total +=aug_img_count\n",
    "    print('Total Augmented images created= ', total)\n",
    "    # create aug_df and merge with train_df to create composite training set ndf\n",
    "    aug_fpaths=[]\n",
    "    aug_labels=[]\n",
    "    classlist=os.listdir(aug_dir)\n",
    "    for klass in classlist:\n",
    "        classpath=os.path.join(aug_dir, klass)\n",
    "        flist=os.listdir(classpath)\n",
    "        for f in flist:\n",
    "            fpath=os.path.join(classpath,f)\n",
    "            aug_fpaths.append(fpath)\n",
    "            aug_labels.append(klass)\n",
    "    Fseries=pd.Series(aug_fpaths, name='filepaths')\n",
    "    Lseries=pd.Series(aug_labels, name='labels')\n",
    "    aug_df=pd.concat([Fseries, Lseries], axis=1)\n",
    "    df=pd.concat([df,aug_df], axis=0).reset_index(drop=True)\n",
    "    print('Length of augmented dataframe is now ', len(df))\n",
    "    return df\n",
    "\n",
    "n=500 # number of samples in each class\n",
    "working_dir=r'./' # directory to store augmented images\n",
    "img_size=(224,224) # size of augmented images\n",
    "train_df=balance(train_df, n, working_dir, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb552178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 327s 4s/step\n",
      "26/26 [==============================] - 112s 4s/step\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_extract_features(df, img_size):\n",
    "    img_data = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        img = cv2.imread(row['filepaths'])\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        img_data.append(img)\n",
    "        labels.append(row['labels'])\n",
    "\n",
    "    img_data = np.array(img_data)\n",
    "    labels = np.array(labels)\n",
    "    return img_data, labels\n",
    "\n",
    "img_size = (224, 224)\n",
    "train_data, train_labels = preprocess_and_extract_features(train_df, img_size)\n",
    "valid_data, valid_labels = preprocess_and_extract_features(valid_df, img_size)\n",
    "\n",
    "\n",
    "# Load ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Extract features\n",
    "train_features = model.predict(train_data)\n",
    "valid_features = model.predict(valid_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9953ea6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation data: 0.38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Doubtful       0.24      0.35      0.28       153\n",
      "     Healthy       0.53      0.36      0.43       328\n",
      "     Minimal       0.38      0.29      0.33       212\n",
      "    Moderate       0.35      0.58      0.44       106\n",
      "      Severe       0.49      0.85      0.62        27\n",
      "\n",
      "    accuracy                           0.38       826\n",
      "   macro avg       0.40      0.49      0.42       826\n",
      "weighted avg       0.41      0.38      0.38       826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "rf_classifier.fit(train_features, train_labels)\n",
    "\n",
    "valid_predictions = rf_classifier.predict(valid_features)\n",
    "\n",
    "# Evaluate the performance of the Random Forest classifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(valid_labels, valid_predictions)\n",
    "print(f'Accuracy on validation data: {accuracy:.2f}')\n",
    "\n",
    "print(classification_report(valid_labels, valid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c60594f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  test_df length:  1656\n",
      "The number of classes in the dataset is:  5\n",
      "            CLASS               IMAGE COUNT \n",
      "           Doubtful                 296     \n",
      "           Healthy                  639     \n",
      "           Minimal                  447     \n",
      "           Moderate                 223     \n",
      "            Severe                  51      \n",
      "Healthy  has the most images=  639   Severe  has the least images=  51\n",
      "average height=  224  average width=  224 aspect ratio=  1.0\n"
     ]
    }
   ],
   "source": [
    "test_path=r'C:\\Users\\deepa\\OneDrive\\Desktop\\major2\\Knee_data_Clahe\\test'\n",
    "list_of_classes=['Healthy','Doubtful','Minimal','Moderate', 'Severe']\n",
    "for d in [test_path]:\n",
    "    filepaths = []\n",
    "    labels=[]\n",
    "    classlist=os.listdir(d)\n",
    "    for klass in classlist:\n",
    "        intklass=int(klass)\n",
    "        label=list_of_classes[intklass]\n",
    "        classpath=os.path.join(d, klass)\n",
    "        flist=os.listdir(classpath)\n",
    "        for f in flist:\n",
    "            fpath=os.path.join(classpath,f)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(label)\n",
    "    Fseries=pd.Series(filepaths, name='filepaths')\n",
    "    Lseries=pd.Series(labels, name='labels')\n",
    "    pdf=pd.concat([Fseries, Lseries], axis=1)\n",
    "    if d == test_path:\n",
    "        test_df=pdf\n",
    "    elif d == valid_path:\n",
    "        valid_df=pdf\n",
    "    else:\n",
    "        train_df=pdf\n",
    "print('  test_df length: ', len(test_df))\n",
    "# get the number of classes and the images count for each class in train_df\n",
    "classes=sorted(list(test_df['labels'].unique()))\n",
    "class_count = len(classes)\n",
    "print('The number of classes in the dataset is: ', class_count)\n",
    "groups=test_df.groupby('labels')\n",
    "print('{0:^30s} {1:^13s}'.format('CLASS', 'IMAGE COUNT'))\n",
    "countlist=[]\n",
    "classlist=[]\n",
    "for label in sorted(list(test_df['labels'].unique())):\n",
    "    group=groups.get_group(label)\n",
    "    countlist.append(len(group))\n",
    "    classlist.append(label)\n",
    "    print('{0:^30s} {1:^13s}'.format(label, str(len(group))))\n",
    "\n",
    "# get the classes with the minimum and maximum number of train images\n",
    "max_value=np.max(countlist)\n",
    "max_index=countlist.index(max_value)\n",
    "max_class=classlist[max_index]\n",
    "min_value=np.min(countlist)\n",
    "min_index=countlist.index(min_value)\n",
    "min_class=classlist[min_index]\n",
    "print(max_class, ' has the most images= ',max_value, ' ', min_class, ' has the least images= ', min_value)\n",
    "# lets get the average height and width of a sample of the train images\n",
    "ht=0\n",
    "wt=0\n",
    "# select 100 random samples of train_df\n",
    "train_df_sample=test_df.sample(n=100, random_state=123,axis=0)\n",
    "for i in range (len(train_df_sample)):\n",
    "    fpath=train_df_sample['filepaths'].iloc[i]\n",
    "    img=plt.imread(fpath)\n",
    "    shape=img.shape\n",
    "    ht += shape[0]\n",
    "    wt += shape[1]\n",
    "print('average height= ', ht//100, ' average width= ', wt//100, 'aspect ratio= ', ht/wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "46cde659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy 639\n",
      "Minimal 447\n",
      "Severe 51\n"
     ]
    }
   ],
   "source": [
    "drop_classes = ['Doubtful','Moderate']\n",
    "\n",
    "test_df = test_df[~test_df['labels'].isin(drop_classes)]\n",
    "\n",
    "# Update the list of classes\n",
    "list_of_classes = [c for c in list_of_classes if c not in drop_classes]\n",
    "\n",
    "# Re-calculate the total classes\n",
    "class_count = len(list_of_classes)\n",
    "\n",
    "# Re-count the images per class\n",
    "groups = test_df.groupby('labels')\n",
    "for label in list_of_classes:\n",
    "    group = groups.get_group(label)\n",
    "    print(label, len(group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c19adaf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after trimming, the maximum samples in any class is now  100  and the minimum samples in any class is  51\n"
     ]
    }
   ],
   "source": [
    "def trim(df, max_samples, min_samples, column):\n",
    "    df=df.copy()\n",
    "    groups=df.groupby(column)\n",
    "    trimmed_df = pd.DataFrame(columns = df.columns)\n",
    "    groups=df.groupby(column)\n",
    "    for label in df[column].unique():\n",
    "        group=groups.get_group(label)\n",
    "        count=len(group)\n",
    "        if count > max_samples:\n",
    "            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)\n",
    "            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "        else:\n",
    "            if count>=min_samples:\n",
    "                sampled_group=group\n",
    "                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "    print('after trimming, the maximum samples in any class is now ',max_samples, ' and the minimum samples in any class is ', min_samples)\n",
    "    return trimmed_df\n",
    "\n",
    "max_samples=100 # since each class has more than 200 images all classes will be trimmed to have 200 images per class\n",
    "min_samples=51\n",
    "column='labels'\n",
    "test_df= trim(test_df, max_samples, min_samples, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36976872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial length of dataframe is  451\n",
      "Found 51 validated image filenames.      for class             Severe             creating  49   augmented images \n",
      "Total Augmented images created=  49\n",
      "Length of augmented dataframe is now  500\n"
     ]
    }
   ],
   "source": [
    "def balance(df, n, working_dir, img_size):\n",
    "    df=df.copy()\n",
    "    print('Initial length of dataframe is ', len(df))\n",
    "    aug_dir=os.path.join(working_dir, 'test_aug')# directory to store augmented images\n",
    "    if os.path.isdir(aug_dir):# start with an empty directory\n",
    "        shutil.rmtree(aug_dir)\n",
    "    os.mkdir(aug_dir)\n",
    "    for label in df['labels'].unique():\n",
    "        dir_path=os.path.join(aug_dir,label)\n",
    "        os.mkdir(dir_path) # make class directories within aug directory\n",
    "    # create and store the augmented images\n",
    "    total=0\n",
    "    gen=ImageDataGenerator(horizontal_flip=True,  rotation_range=20, width_shift_range=.2,\n",
    "                                  height_shift_range=.2, zoom_range=.2)\n",
    "    groups=df.groupby('labels') # group by class\n",
    "    for label in df['labels'].unique():  # for every class\n",
    "        group=groups.get_group(label)  # a dataframe holding only rows with the specified label\n",
    "        sample_count=len(group)   # determine how many samples there are in this class\n",
    "        if sample_count< n: # if the class has less than target number of images\n",
    "            aug_img_count=0\n",
    "            delta=n - sample_count  # number of augmented images to create\n",
    "            target_dir=os.path.join(aug_dir, label)  # define where to write the images\n",
    "            msg='{0:40s} for class {1:^30s} creating {2:^5s} augmented images'.format(' ', label, str(delta))\n",
    "            print(msg, '\\r', end='') # prints over on the same line\n",
    "            aug_gen=gen.flow_from_dataframe( group,  x_col='filepaths', y_col=None, target_size=img_size,\n",
    "                                            class_mode=None, batch_size=1, shuffle=False,\n",
    "                                            save_to_dir=target_dir, save_prefix='aug-', color_mode='rgb',\n",
    "                                            save_format='jpg')\n",
    "            while aug_img_count<delta:\n",
    "                images=next(aug_gen)\n",
    "                aug_img_count += len(images)\n",
    "            total +=aug_img_count\n",
    "    print('Total Augmented images created= ', total)\n",
    "    # create aug_df and merge with train_df to create composite training set ndf\n",
    "    aug_fpaths=[]\n",
    "    aug_labels=[]\n",
    "    classlist=os.listdir(aug_dir)\n",
    "    for klass in classlist:\n",
    "        classpath=os.path.join(aug_dir, klass)\n",
    "        flist=os.listdir(classpath)\n",
    "        for f in flist:\n",
    "            fpath=os.path.join(classpath,f)\n",
    "            aug_fpaths.append(fpath)\n",
    "            aug_labels.append(klass)\n",
    "    Fseries=pd.Series(aug_fpaths, name='filepaths')\n",
    "    Lseries=pd.Series(aug_labels, name='labels')\n",
    "    aug_df=pd.concat([Fseries, Lseries], axis=1)\n",
    "    df=pd.concat([df,aug_df], axis=0).reset_index(drop=True)\n",
    "    print('Length of augmented dataframe is now ', len(df))\n",
    "    return df\n",
    "\n",
    "n=100 # number of samples in each class\n",
    "working_dir=r'./' # directory to store augmented images\n",
    "img_size=(224,224) # size of augmented images\n",
    "test_df=balance(test_df, n, working_dir, img_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a9d4f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 63s 4s/step\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_extract_features1(df, img_size):\n",
    "    img_data = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        img = cv2.imread(row['filepaths'])\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        img_data.append(img)\n",
    "        labels.append(row['labels'])\n",
    "\n",
    "    img_data = np.array(img_data)\n",
    "    labels = np.array(labels)\n",
    "    return img_data, labels\n",
    "\n",
    "\n",
    "test_data1, test_labels1 = preprocess_and_extract_features1(test_df, img_size)\n",
    "\n",
    "\n",
    "# Extract features\n",
    "test_features1 = model.predict(test_data1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab7148bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.41\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy on the test data\n",
    "test_predictions = rf_classifier.predict(test_features1)\n",
    "test_accuracy = accuracy_score(test_labels1, test_predictions)\n",
    "print(f'Accuracy on test data: {test_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c82e6dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Doubtful       0.31      0.34      0.33       100\n",
      "     Healthy       0.32      0.39      0.35       100\n",
      "     Minimal       0.31      0.19      0.24       100\n",
      "    Moderate       0.33      0.37      0.35       100\n",
      "      Severe       0.76      0.74      0.75       100\n",
      "\n",
      "    accuracy                           0.41       500\n",
      "   macro avg       0.41      0.41      0.40       500\n",
      "weighted avg       0.41      0.41      0.40       500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[34 34 11 21  0]\n",
      " [34 39 15 11  1]\n",
      " [16 37 19 21  7]\n",
      " [21 11 15 37 16]\n",
      " [ 4  0  1 21 74]]\n",
      "Precision: 0.41\n",
      "Recall: 0.41\n",
      "F1 Score: 0.41\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(test_labels1, test_predictions)\n",
    "precision = precision_score(test_labels1, test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "recall = recall_score(test_labels1, test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "f1 = f1_score(test_labels1, test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "print(classification_report(test_labels1, test_predictions))\n",
    "\n",
    "# Print the results\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96a326c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Moderate\n",
      "Healthy   Moderate\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Minimal\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Severe\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Moderate\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Minimal\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Moderate\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Minimal\n",
      "Minimal   Severe\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Moderate\n",
      "Minimal   Severe\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Severe\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Severe\n",
      "Minimal   Doubtful\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Doubtful\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Severe\n",
      "Minimal   Doubtful\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Severe\n",
      "Minimal   Severe\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Doubtful\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Doubtful\n",
      "Moderate   Minimal\n",
      "Moderate   Doubtful\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Minimal\n",
      "Moderate   Healthy\n",
      "Moderate   Healthy\n",
      "Moderate   Doubtful\n",
      "Moderate   Doubtful\n",
      "Moderate   Minimal\n",
      "Moderate   Severe\n",
      "Moderate   Doubtful\n",
      "Moderate   Minimal\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Healthy\n",
      "Moderate   Healthy\n",
      "Moderate   Minimal\n",
      "Moderate   Healthy\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Healthy\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Minimal\n",
      "Moderate   Severe\n",
      "Moderate   Severe\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Severe\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Doubtful\n",
      "Moderate   Doubtful\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Doubtful\n",
      "Moderate   Minimal\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Minimal\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Minimal\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Doubtful\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Doubtful\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Doubtful\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Doubtful\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_labels1)):\n",
    "    print(test_labels1[i],\" \", test_predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8df6c8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "Image 1: Actual Label: 0, Predicted Label: Healthy\n",
      "Image 2: Actual Label: 0, Predicted Label: Healthy\n",
      "Image 3: Actual Label: 0, Predicted Label: Healthy\n",
      "Image 4: Actual Label: 0, Predicted Label: Healthy\n",
      "Image 5: Actual Label: 0, Predicted Label: Healthy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Define the directory paths for classes 0, 3, and 4\n",
    "class_directories = {\n",
    "    '0': r'C:\\Users\\deepa\\OneDrive\\Desktop\\major\\knee\\test\\0',\n",
    "   # '3': '/content/drive/MyDrive/Colab Notebooks/Knee_data_Clahe/test/3',\n",
    "    '4': r'C:\\Users\\deepa\\OneDrive\\Desktop\\major\\knee\\train\\4'\n",
    "}\n",
    "\n",
    "# Specify the number of random images to select\n",
    "num_random_images = 5\n",
    "\n",
    "# Initialize lists to store actual and predicted labels\n",
    "actual_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Select random images from the specified classes\n",
    "for label, directory in class_directories.items():\n",
    "    image_files = os.listdir(directory)\n",
    "    random_images = random.sample(image_files, num_random_images)\n",
    "    for image_file in random_images:\n",
    "        actual_labels.append(label)\n",
    "        image_path = os.path.join(directory, image_file)\n",
    "\n",
    "        # Preprocess and extract features from the image\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=0)  # Reshape to match model input\n",
    "\n",
    "        # Use the trained Random Forest classifier to predict the label\n",
    "        predicted_label = rf_classifier.predict(model.predict(img))\n",
    "        predicted_labels.append(predicted_label[0])\n",
    "\n",
    "# Display the actual and predicted labels for each image\n",
    "for i in range(num_random_images):\n",
    "    actual_label = actual_labels[i]\n",
    "    predicted_label = predicted_labels[i]\n",
    "    print(f\"Image {i + 1}: Actual Label: {actual_label}, Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad586df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d316c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
