{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eba88c99",
   "metadata": {},
   "source": [
    "## impoats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a82ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.sys.path\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.applications import  ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras import backend as K\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173e3712",
   "metadata": {},
   "source": [
    "## trim balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17f81486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(df, max_samples, min_samples, column):\n",
    "    df=df.copy()\n",
    "    groups=df.groupby(column)\n",
    "    trimmed_df = pd.DataFrame(columns = df.columns)\n",
    "    groups=df.groupby(column)\n",
    "    for label in df[column].unique():\n",
    "        group=groups.get_group(label)\n",
    "        count=len(group)\n",
    "        if count > max_samples:\n",
    "            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)\n",
    "            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "        else:\n",
    "            if count>=min_samples:\n",
    "                sampled_group=group\n",
    "                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "    print('after trimming, the maximum samples in any class is now ',max_samples, ' and the minimum samples in any class is ', min_samples)\n",
    "    return trimmed_df\n",
    "def balance(df, n, working_dir, img_size):\n",
    "    df=df.copy()\n",
    "    print('Initial length of dataframe is ', len(df))\n",
    "    aug_dir=os.path.join(working_dir, 'aug')# directory to store augmented images\n",
    "    if os.path.isdir(aug_dir):# start with an empty directory\n",
    "        shutil.rmtree(aug_dir)\n",
    "    os.mkdir(aug_dir)\n",
    "    for label in df['labels'].unique():\n",
    "        dir_path=os.path.join(aug_dir,label)\n",
    "        os.mkdir(dir_path) # make class directories within aug directory\n",
    "    # create and store the augmented images\n",
    "    total=0\n",
    "    gen=ImageDataGenerator(horizontal_flip=True,  rotation_range=20, width_shift_range=.2,\n",
    "                                  height_shift_range=.2, zoom_range=.2)\n",
    "    groups=df.groupby('labels') # group by class\n",
    "    for label in df['labels'].unique():  # for every class\n",
    "        group=groups.get_group(label)  # a dataframe holding only rows with the specified label\n",
    "        sample_count=len(group)   # determine how many samples there are in this class\n",
    "        if sample_count< n: # if the class has less than target number of images\n",
    "            aug_img_count=0\n",
    "            delta=n - sample_count  # number of augmented images to create\n",
    "            target_dir=os.path.join(aug_dir, label)  # define where to write the images\n",
    "            msg='{0:40s} for class {1:^30s} creating {2:^5s} augmented images'.format(' ', label, str(delta))\n",
    "            print(msg, '\\r', end='') # prints over on the same line\n",
    "            aug_gen=gen.flow_from_dataframe( group,  x_col='filepaths', y_col=None, target_size=img_size,\n",
    "                                            class_mode=None, batch_size=1, shuffle=False,\n",
    "                                            save_to_dir=target_dir, save_prefix='aug-', color_mode='rgb',\n",
    "                                            save_format='jpg')\n",
    "            while aug_img_count<delta:\n",
    "                images=next(aug_gen)\n",
    "                aug_img_count += len(images)\n",
    "            total +=aug_img_count\n",
    "    print('Total Augmented images created= ', total)\n",
    "    # create aug_df and merge with train_df to create composite training set ndf\n",
    "    aug_fpaths=[]\n",
    "    aug_labels=[]\n",
    "    classlist=os.listdir(aug_dir)\n",
    "    for klass in classlist:\n",
    "        classpath=os.path.join(aug_dir, klass)\n",
    "        flist=os.listdir(classpath)\n",
    "        for f in flist:\n",
    "            fpath=os.path.join(classpath,f)\n",
    "            aug_fpaths.append(fpath)\n",
    "            aug_labels.append(klass)\n",
    "    Fseries=pd.Series(aug_fpaths, name='filepaths')\n",
    "    Lseries=pd.Series(aug_labels, name='labels')\n",
    "    aug_df=pd.concat([Fseries, Lseries], axis=1)\n",
    "    df=pd.concat([df,aug_df], axis=0).reset_index(drop=True)\n",
    "    print('Length of augmented dataframe is now ', len(df))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aa691e",
   "metadata": {},
   "source": [
    "## df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfb06ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df lenght:  5839   test_df length:  1656   valid_df length:  826\n",
      "The number of classes in the dataset is:  5\n",
      "            CLASS               IMAGE COUNT \n",
      "           Doubtful                1046     \n",
      "           Healthy                 2286     \n",
      "           Minimal                 1516     \n",
      "           Moderate                 802     \n",
      "            Severe                  189     \n",
      "Healthy  has the most images=  2286   Severe  has the least images=  189\n",
      "average height=  224  average width=  224 aspect ratio=  1.0\n"
     ]
    }
   ],
   "source": [
    "\"D:\\\\Knee_data_Clahe\\\\cropped\\\\train\"\n",
    "IMGSZ= (224,224)\n",
    "# train_path=\"C:\\\\Users\\\\91745\\\\Documents\\\\Datasets\\\\knee\\\\train\" \n",
    "# test_path= \"C:\\\\Users\\\\91745\\\\Documents\\\\Datasets\\\\knee\\\\test\" \n",
    "# valid_path=\"C:\\\\Users\\\\91745\\\\Documents\\\\Datasets\\\\knee\\\\val\" \n",
    "\n",
    "train_path=\"D:\\\\Knee_data_Clahe\\\\train\" \n",
    "test_path= \"D:\\\\Knee_data_Clahe\\\\test\" \n",
    "valid_path= \"D:\\\\Knee_data_Clahe\\\\val\" \n",
    "\n",
    "# train_path=\"D:\\\\Knee_data_Clahe\\\\cropped\\\\train\" \n",
    "# test_path= \"D:\\\\Knee_data_Clahe\\\\cropped\\\\test\" \n",
    "# valid_path= \"D:\\\\Knee_data_Clahe\\\\cropped\\\\val\" \n",
    "\n",
    "# train_path=\"D:\\\\cropped_knees\\\\train\"\n",
    "# test_path= \"D:\\\\cropped_knees\\\\test\" \n",
    "# valid_path=\"D:\\\\cropped_knees\\\\val\" \n",
    "\n",
    "\n",
    "\n",
    "list_of_classes=['Healthy', 'Doubtful', 'Minimal', 'Moderate', 'Severe']\n",
    "for d in [train_path, test_path, valid_path]:\n",
    "    filepaths = []\n",
    "    labels=[] \n",
    "    classlist=os.listdir(d)   \n",
    "    for klass in classlist:\n",
    "        intklass=int(klass)\n",
    "        label=list_of_classes[intklass]\n",
    "        classpath=os.path.join(d, klass)\n",
    "        flist=os.listdir(classpath)        \n",
    "        for f in flist:\n",
    "            fpath=os.path.join(classpath,f)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(label)\n",
    "    Fseries=pd.Series(filepaths, name='filepaths')\n",
    "    Lseries=pd.Series(labels, name='labels')        \n",
    "    pdf=pd.concat([Fseries, Lseries], axis=1)\n",
    "    if d == test_path:\n",
    "        test_df=pdf\n",
    "    elif d == valid_path:\n",
    "        valid_df=pdf\n",
    "    else:\n",
    "        train_df=pdf\n",
    "print('train_df lenght: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))\n",
    "# get the number of classes and the images count for each class in train_df\n",
    "classes=sorted(list(train_df['labels'].unique()))\n",
    "class_count = len(classes)\n",
    "print('The number of classes in the dataset is: ', class_count)\n",
    "groups=train_df.groupby('labels')\n",
    "print('{0:^30s} {1:^13s}'.format('CLASS', 'IMAGE COUNT'))\n",
    "countlist=[]\n",
    "classlist=[]\n",
    "for label in sorted(list(train_df['labels'].unique())):\n",
    "    group=groups.get_group(label)\n",
    "    countlist.append(len(group))\n",
    "    classlist.append(label)\n",
    "    print('{0:^30s} {1:^13s}'.format(label, str(len(group))))\n",
    "\n",
    "# get the classes with the minimum and maximum number of train images\n",
    "max_value=np.max(countlist)\n",
    "max_index=countlist.index(max_value)\n",
    "max_class=classlist[max_index]\n",
    "min_value=np.min(countlist)\n",
    "min_index=countlist.index(min_value)\n",
    "min_class=classlist[min_index]\n",
    "print(max_class, ' has the most images= ',max_value, ' ', min_class, ' has the least images= ', min_value)\n",
    "# lets get the average height and width of a sample of the train images\n",
    "ht=0\n",
    "wt=0\n",
    "# select 100 random samples of train_df\n",
    "train_df_sample=train_df.sample(n=100, random_state=123,axis=0)\n",
    "for i in range (len(train_df_sample)):\n",
    "    fpath=train_df_sample['filepaths'].iloc[i]\n",
    "    img=plt.imread(fpath)\n",
    "    shape=img.shape\n",
    "    ht += shape[0]\n",
    "    wt += shape[1]\n",
    "print('average height= ', ht//100, ' average width= ', wt//100, 'aspect ratio= ', ht/wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fabdaed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderate 802\n",
      "Severe 189\n"
     ]
    }
   ],
   "source": [
    "# Drop specified classes\n",
    "\n",
    "drop_classes = ['Healthy', 'Doubtful', 'Minimal' ]\n",
    "\n",
    "train_df = train_df[~train_df['labels'].isin(drop_classes)]\n",
    "valid_df = valid_df[~valid_df['labels'].isin(drop_classes)]  \n",
    "test_df = test_df[~test_df['labels'].isin(drop_classes)]\n",
    "\n",
    "# Update the list of classes \n",
    "list_of_classes = [c for c in list_of_classes if c not in drop_classes]\n",
    "\n",
    "# Re-calculate the total classes\n",
    "class_count = len(list_of_classes)\n",
    "\n",
    "# Re-count the images per class\n",
    "groups = train_df.groupby('labels')  \n",
    "for label in list_of_classes:\n",
    "    group = groups.get_group(label) \n",
    "    print(label, len(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9d027",
   "metadata": {},
   "source": [
    "## using balance and trim on train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c030727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial length of dataframe is  991\n",
      "Found 189 validated image filenames.     for class             Severe             creating  311  augmented images \n",
      "Total Augmented images created=  311\n",
      "Length of augmented dataframe is now  1302\n",
      "after trimming, the maximum samples in any class is now  500  and the minimum samples in any class is  189\n"
     ]
    }
   ],
   "source": [
    "n=500 # number of samples in each class\n",
    "working_dir=r'./' # directory to store augmented images\n",
    "img_size=(224,224) # size of augmented images\n",
    "train_df=balance(train_df, n, working_dir, img_size)\n",
    "\n",
    "\n",
    "max_samples=500 # since each class has more than 200 images all classes will be trimmed to have 200 images per class\n",
    "min_samples=189\n",
    "column='labels'\n",
    "train_df= trim(train_df, max_samples, min_samples, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43c71508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moderate    500\n",
      "Severe      500\n",
      "Name: labels, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print (train_df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e497f2c7",
   "metadata": {},
   "source": [
    "## feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb552178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 6s 162ms/step\n",
      "5/5 [==============================] - 1s 154ms/step\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_extract_features(df, img_size):\n",
    "    img_data = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        img = cv2.imread(row['filepaths'])\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        img_data.append(img)\n",
    "        labels.append(row['labels'])\n",
    "\n",
    "    img_data = np.array(img_data)\n",
    "    labels = np.array(labels)\n",
    "    return img_data, labels\n",
    "\n",
    "img_size = (224, 224)\n",
    "train_data, train_labels = preprocess_and_extract_features(train_df, img_size)\n",
    "valid_data, valid_labels = preprocess_and_extract_features(valid_df, img_size)\n",
    "\n",
    "\n",
    "# Load ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Extract features\n",
    "train_features = model.predict(train_data)\n",
    "valid_features = model.predict(valid_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90243d83",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9953ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=123)\n",
    "rf_classifier.fit(train_features, train_labels)\n",
    "\n",
    "valid_predictions = rf_classifier.predict(valid_features)\n",
    "\n",
    "# Evaluate the performance of the Random Forest classifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(valid_labels, valid_predictions)\n",
    "print(f'Accuracy on validation data: {accuracy:.2f}')\n",
    "\n",
    "print(classification_report(valid_labels, valid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60594f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (test_df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f39c6d",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9347642",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', random_state=123, C=1.0)\n",
    "svm_classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Predict using the trained SVM classifier\n",
    "valid_predictions_svm = svm_classifier.predict(valid_features)\n",
    "\n",
    "# Evaluate the performance of the SVM classifier\n",
    "accuracy_svm = accuracy_score(valid_labels, valid_predictions_svm)\n",
    "print(f'Accuracy on validation data (SVM): {accuracy_svm:.2f}')\n",
    "\n",
    "print(classification_report(valid_labels, valid_predictions_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b805e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2bb8d07",
   "metadata": {},
   "source": [
    "## extract features of test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a78f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58edc198",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1fb8ca90",
   "metadata": {},
   "source": [
    "## extract test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9d4f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_extract_features1(df, img_size):\n",
    "    img_data = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        img = cv2.imread(row['filepaths'])\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        img_data.append(img)\n",
    "        labels.append(row['labels'])\n",
    "\n",
    "    img_data = np.array(img_data)\n",
    "    labels = np.array(labels)\n",
    "    return img_data, labels\n",
    "\n",
    "\n",
    "test_data1, test_labels1 = preprocess_and_extract_features1(test_df, img_size)\n",
    "\n",
    "\n",
    "# Extract features\n",
    "test_features1 = model.predict(test_data1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920d737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy on the test data\n",
    "\n",
    "\n",
    "\n",
    "# the origanl code\n",
    "# test_predictions = rf_classifier.predict(test_features1)\n",
    "# test_accuracy = accuracy_score(test_labels1, test_predictions)\n",
    "# print(f'Accuracy on test data: {test_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6acaae3",
   "metadata": {},
   "source": [
    "# results both "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908880a7",
   "metadata": {},
   "source": [
    "## randon forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82e6dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy on the test data\n",
    "rf_test_predictions = rf_classifier.predict(test_features1)\n",
    "rf_test_accuracy = accuracy_score(test_labels1, rf_test_predictions)\n",
    "print(f'Accuracy on test data: {rf_test_accuracy:.2f}')\n",
    "\n",
    "\n",
    "rconf_matrix = confusion_matrix(test_labels1, rf_test_predictions)\n",
    "rprecision = precision_score(test_labels1, rf_test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "rrecall = recall_score(test_labels1, rf_test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "rf1 = f1_score(test_labels1, rf_test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "print(classification_report(test_labels1, rf_test_predictions))\n",
    "\n",
    "# Print the results\n",
    "print(f'Confusion Matrix:\\n{rconf_matrix}')\n",
    "print(f'Precision: {rprecision:.2f}')\n",
    "print(f'Recall: {rrecall:.2f}')\n",
    "print(f'F1 Score: {rf1:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1afd3b",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8735c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy on the test data\n",
    "svm_test_predictions = svm_classifier.predict(test_features1)\n",
    "svm_test_accuracy = accuracy_score(test_labels1, svm_test_predictions)\n",
    "print(f'Accuracy on test data: {svm_test_accuracy:.2f}')\n",
    "\n",
    "\n",
    "sconf_matrix = confusion_matrix(test_labels1, svm_test_predictions)\n",
    "sprecision = precision_score(test_labels1, svm_test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "srecall = recall_score(test_labels1, svm_test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "sf1 = f1_score(test_labels1, svm_test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "print(classification_report(test_labels1, svm_test_predictions))\n",
    "\n",
    "# Print the results\n",
    "print(f'Confusion Matrix:\\n{sconf_matrix}')\n",
    "print(f'Precision: {sprecision:.2f}')\n",
    "print(f'Recall: {srecall:.2f}')\n",
    "print(f'F1 Score: {sf1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96a326c9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Moderate\n",
      "Healthy   Moderate\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Minimal\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Severe\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Moderate\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Minimal\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Moderate\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Minimal\n",
      "Minimal   Severe\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Moderate\n",
      "Minimal   Severe\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Severe\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Severe\n",
      "Minimal   Doubtful\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Doubtful\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Severe\n",
      "Minimal   Doubtful\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Severe\n",
      "Minimal   Severe\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Doubtful\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Doubtful\n",
      "Moderate   Minimal\n",
      "Moderate   Doubtful\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Minimal\n",
      "Moderate   Healthy\n",
      "Moderate   Healthy\n",
      "Moderate   Doubtful\n",
      "Moderate   Doubtful\n",
      "Moderate   Minimal\n",
      "Moderate   Severe\n",
      "Moderate   Doubtful\n",
      "Moderate   Minimal\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Healthy\n",
      "Moderate   Healthy\n",
      "Moderate   Minimal\n",
      "Moderate   Healthy\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Healthy\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Minimal\n",
      "Moderate   Severe\n",
      "Moderate   Severe\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Severe\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Doubtful\n",
      "Moderate   Doubtful\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Doubtful\n",
      "Moderate   Minimal\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Minimal\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Minimal\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Doubtful\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Doubtful\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Doubtful\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Doubtful\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8df6c8e6",
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "Image 1: Actual Label: 0, Predicted Label: Healthy\n",
      "Image 2: Actual Label: 0, Predicted Label: Healthy\n",
      "Image 3: Actual Label: 0, Predicted Label: Healthy\n",
      "Image 4: Actual Label: 0, Predicted Label: Healthy\n",
      "Image 5: Actual Label: 0, Predicted Label: Healthy\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4d9987f",
   "metadata": {},
   "source": [
    "# result balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d316c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (test_df['labels'].value_counts())\n",
    "max_samples=51\n",
    "# since each class has more than 200 images all classes will be trimmed to have 200 images per class\n",
    "min_samples=51\n",
    "column='labels'\n",
    "test_df= trim(test_df, max_samples, min_samples, column)\n",
    "\n",
    "\n",
    "n=52 # number of samples in each class\n",
    "working_dir=r'./' # directory to store augmented images\n",
    "img_size=IMGSZ # size of augmented images\n",
    "test_df=balance(test_df, n, working_dir, img_size) \n",
    "\n",
    "print(\"\")\n",
    "print (test_df['labels'].value_counts())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8369f31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_extract_features1(df, img_size):\n",
    "    img_data = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        img = cv2.imread(row['filepaths'])\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        img_data.append(img)\n",
    "        labels.append(row['labels'])\n",
    "\n",
    "    img_data = np.array(img_data)\n",
    "    labels = np.array(labels)\n",
    "    return img_data, labels\n",
    "\n",
    "\n",
    "test_data1, test_labels1 = preprocess_and_extract_features1(test_df, img_size)\n",
    "\n",
    "\n",
    "# Extract features\n",
    "test_features1 = model.predict(test_data1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cab37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy on the test data\n",
    "rf_test_predictions = rf_classifier.predict(test_features1)\n",
    "rf_test_accuracy = accuracy_score(test_labels1, rf_test_predictions)\n",
    "print(f'Accuracy on test data: {rf_test_accuracy:.2f}')\n",
    "\n",
    "\n",
    "rconf_matrix = confusion_matrix(test_labels1, rf_test_predictions)\n",
    "rprecision = precision_score(test_labels1, rf_test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "rrecall = recall_score(test_labels1, rf_test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "rf1 = f1_score(test_labels1, rf_test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "print(classification_report(test_labels1, rf_test_predictions))\n",
    "\n",
    "# Print the results\n",
    "print(f'Confusion Matrix:\\n{rconf_matrix}')\n",
    "print(f'Precision: {rprecision:.2f}')\n",
    "print(f'Recall: {rrecall:.2f}')\n",
    "print(f'F1 Score: {rf1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df25170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the accuracy on the test data\n",
    "svm_test_predictions = svm_classifier.predict(test_features1)\n",
    "svm_test_accuracy = accuracy_score(test_labels1, svm_test_predictions)\n",
    "print(f'Accuracy on test data: {svm_test_accuracy:.2f}')\n",
    "\n",
    "\n",
    "sconf_matrix = confusion_matrix(test_labels1, svm_test_predictions)\n",
    "sprecision = precision_score(test_labels1, svm_test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "srecall = recall_score(test_labels1, svm_test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "sf1 = f1_score(test_labels1, svm_test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "print(classification_report(test_labels1, svm_test_predictions))\n",
    "\n",
    "# Print the results\n",
    "print(f'Confusion Matrix:\\n{sconf_matrix}')\n",
    "print(f'Precision: {sprecision:.2f}')\n",
    "print(f'Recall: {srecall:.2f}')\n",
    "print(f'F1 Score: {sf1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dc0b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2921f68",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# random code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701b444b",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_labels1)):\n",
    "    print(test_labels1[i],\" \", test_predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f30ba48",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Define the directory paths for classes 0, 3, and 4\n",
    "class_directories = {\n",
    "    '0': r'C:\\Users\\deepa\\OneDrive\\Desktop\\major\\knee\\test\\0',\n",
    "   # '3': '/content/drive/MyDrive/Colab Notebooks/Knee_data_Clahe/test/3',\n",
    "    '4': r'C:\\Users\\deepa\\OneDrive\\Desktop\\major\\knee\\train\\4'\n",
    "}\n",
    "\n",
    "# Specify the number of random images to select\n",
    "num_random_images = 5\n",
    "\n",
    "# Initialize lists to store actual and predicted labels\n",
    "actual_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Select random images from the specified classes\n",
    "for label, directory in class_directories.items():\n",
    "    image_files = os.listdir(directory)\n",
    "    random_images = random.sample(image_files, num_random_images)\n",
    "    for image_file in random_images:\n",
    "        actual_labels.append(label)\n",
    "        image_path = os.path.join(directory, image_file)\n",
    "\n",
    "        # Preprocess and extract features from the image\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=0)  # Reshape to match model input\n",
    "\n",
    "        # Use the trained Random Forest classifier to predict the label\n",
    "        predicted_label = rf_classifier.predict(model.predict(img))\n",
    "        predicted_labels.append(predicted_label[0])\n",
    "\n",
    "# Display the actual and predicted labels for each image\n",
    "for i in range(num_random_images):\n",
    "    actual_label = actual_labels[i]\n",
    "    predicted_label = predicted_labels[i]\n",
    "    print(f\"Image {i + 1}: Actual Label: {actual_label}, Predicted Label: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
