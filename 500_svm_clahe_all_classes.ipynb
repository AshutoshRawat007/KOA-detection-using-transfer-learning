{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22bf6618",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a82ebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.sys.path\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.applications import  ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "from tensorflow.keras import backend as K\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b44802c",
   "metadata": {},
   "source": [
    "## balance and trim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be2041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(df, max_samples, min_samples, column):\n",
    "    df=df.copy()\n",
    "    groups=df.groupby(column)    \n",
    "    trimmed_df = pd.DataFrame(columns = df.columns)\n",
    "    groups=df.groupby(column)\n",
    "    for label in df[column].unique(): \n",
    "        group=groups.get_group(label)\n",
    "        count=len(group)    \n",
    "        if count > max_samples:\n",
    "            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)\n",
    "            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "        else:\n",
    "            if count>=min_samples:\n",
    "                sampled_group=group        \n",
    "                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "    print('after trimming, the maximum samples in any class is now ',max_samples, ' and the minimum samples in any class is ', min_samples)\n",
    "    return trimmed_df\n",
    "\n",
    "def balance(df, n, working_dir, img_size):\n",
    "    df=df.copy()\n",
    "    print('Initial length of dataframe is ', len(df))\n",
    "    aug_dir=os.path.join(working_dir, 'aug')# directory to store augmented images\n",
    "    if os.path.isdir(aug_dir):# start with an empty directory\n",
    "        shutil.rmtree(aug_dir)\n",
    "    os.mkdir(aug_dir)        \n",
    "    for label in df['labels'].unique():    \n",
    "        dir_path=os.path.join(aug_dir,label)    \n",
    "        os.mkdir(dir_path) # make class directories within aug directory\n",
    "    # create and store the augmented images  \n",
    "    total=0\n",
    "    gen=ImageDataGenerator(horizontal_flip=True,  rotation_range=20, width_shift_range=.2,\n",
    "                                  height_shift_range=.2, zoom_range=.2)\n",
    "    groups=df.groupby('labels') # group by class\n",
    "    for label in df['labels'].unique():  # for every class               \n",
    "        group=groups.get_group(label)  # a dataframe holding only rows with the specified label \n",
    "        sample_count=len(group)   # determine how many samples there are in this class  \n",
    "        if sample_count< n: # if the class has less than target number of images\n",
    "            aug_img_count=0\n",
    "            delta=n - sample_count  # number of augmented images to create\n",
    "            target_dir=os.path.join(aug_dir, label)  # define where to write the images\n",
    "            msg='{0:40s} for class {1:^30s} creating {2:^5s} augmented images'.format(' ', label, str(delta))\n",
    "            print(msg, '\\r', end='') # prints over on the same line\n",
    "            aug_gen=gen.flow_from_dataframe( group,  x_col='filepaths', y_col=None, target_size=img_size,\n",
    "                                            class_mode=None, batch_size=1, shuffle=False, \n",
    "                                            save_to_dir=target_dir, save_prefix='aug-', color_mode='rgb',\n",
    "                                            save_format='jpg')\n",
    "            while aug_img_count<delta:\n",
    "                images=next(aug_gen)            \n",
    "                aug_img_count += len(images)\n",
    "            total +=aug_img_count\n",
    "    print('Total Augmented images created= ', total)\n",
    "    # create aug_df and merge with train_df to create composite training set ndf\n",
    "    aug_fpaths=[]\n",
    "    aug_labels=[]\n",
    "    classlist=os.listdir(aug_dir)\n",
    "    for klass in classlist:\n",
    "        classpath=os.path.join(aug_dir, klass)     \n",
    "        flist=os.listdir(classpath)    \n",
    "        for f in flist:        \n",
    "            fpath=os.path.join(classpath,f)         \n",
    "            aug_fpaths.append(fpath)\n",
    "            aug_labels.append(klass)\n",
    "    Fseries=pd.Series(aug_fpaths, name='filepaths')\n",
    "    Lseries=pd.Series(aug_labels, name='labels')\n",
    "    aug_df=pd.concat([Fseries, Lseries], axis=1)         \n",
    "    df=pd.concat([df,aug_df], axis=0).reset_index(drop=True)\n",
    "    print('Length of augmented dataframe is now ', len(df))\n",
    "    return df \n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefe8aa2",
   "metadata": {},
   "source": [
    "## df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfb06ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_df lenght:  5839   valid_df length:  826\n",
      "The number of classes in the dataset is:  5\n",
      "            CLASS               IMAGE COUNT \n",
      "           Doubtful                1046     \n",
      "           Healthy                 2286     \n",
      "           Minimal                 1516     \n",
      "           Moderate                 802     \n",
      "            Severe                  189     \n",
      "Healthy  has the most images=  2286   Severe  has the least images=  189\n",
      "average height=  224  average width=  224 aspect ratio=  1.0\n"
     ]
    }
   ],
   "source": [
    "\"D:\\\\Knee_data_Clahe\\\\cropped\\\\train\"\n",
    "IMGSZ= (224,224)\n",
    "# train_path=\"C:\\\\Users\\\\91745\\\\Documents\\\\Datasets\\\\knee\\\\train\" \n",
    "# test_path= \"C:\\\\Users\\\\91745\\\\Documents\\\\Datasets\\\\knee\\\\test\" \n",
    "# valid_path=\"C:\\\\Users\\\\91745\\\\Documents\\\\Datasets\\\\knee\\\\val\" \n",
    "\n",
    "train_path=\"D:\\\\Knee_data_Clahe\\\\train\" \n",
    "test_path= \"D:\\\\Knee_data_Clahe\\\\test\" \n",
    "valid_path= \"D:\\\\Knee_data_Clahe\\\\val\" \n",
    "\n",
    "# train_path=\"D:\\\\Knee_data_Clahe\\\\cropped\\\\train\" \n",
    "# test_path= \"D:\\\\Knee_data_Clahe\\\\cropped\\\\test\" \n",
    "# valid_path= \"D:\\\\Knee_data_Clahe\\\\cropped\\\\val\" \n",
    "\n",
    "# train_path=\"D:\\\\cropped_knees\\\\train\"\n",
    "# test_path= \"D:\\\\cropped_knees\\\\test\" \n",
    "# valid_path=\"D:\\\\cropped_knees\\\\val\" \n",
    "\n",
    "\n",
    "\n",
    "list_of_classes=['Healthy', 'Doubtful', 'Minimal', 'Moderate', 'Severe']\n",
    "for d in [train_path, test_path, valid_path]:\n",
    "    filepaths = []\n",
    "    labels=[] \n",
    "    classlist=os.listdir(d)   \n",
    "    for klass in classlist:\n",
    "        intklass=int(klass)\n",
    "        label=list_of_classes[intklass]\n",
    "        classpath=os.path.join(d, klass)\n",
    "        flist=os.listdir(classpath)        \n",
    "        for f in flist:\n",
    "            fpath=os.path.join(classpath,f)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(label)\n",
    "    Fseries=pd.Series(filepaths, name='filepaths')\n",
    "    Lseries=pd.Series(labels, name='labels')        \n",
    "    pdf=pd.concat([Fseries, Lseries], axis=1)\n",
    "    if d == test_path:\n",
    "        test_df=pdf\n",
    "    elif d == valid_path:\n",
    "        valid_df=pdf\n",
    "    else:\n",
    "        train_df=pdf\n",
    "print('train_df lenght: ', len(train_df), '  test_df length: ', len(test_df), '  valid_df length: ', len(valid_df))\n",
    "# get the number of classes and the images count for each class in train_df\n",
    "classes=sorted(list(train_df['labels'].unique()))\n",
    "class_count = len(classes)\n",
    "print('The number of classes in the dataset is: ', class_count)\n",
    "groups=train_df.groupby('labels')\n",
    "print('{0:^30s} {1:^13s}'.format('CLASS', 'IMAGE COUNT'))\n",
    "countlist=[]\n",
    "classlist=[]\n",
    "for label in sorted(list(train_df['labels'].unique())):\n",
    "    group=groups.get_group(label)\n",
    "    countlist.append(len(group))\n",
    "    classlist.append(label)\n",
    "    print('{0:^30s} {1:^13s}'.format(label, str(len(group))))\n",
    "\n",
    "# get the classes with the minimum and maximum number of train images\n",
    "max_value=np.max(countlist)\n",
    "max_index=countlist.index(max_value)\n",
    "max_class=classlist[max_index]\n",
    "min_value=np.min(countlist)\n",
    "min_index=countlist.index(min_value)\n",
    "min_class=classlist[min_index]\n",
    "print(max_class, ' has the most images= ',max_value, ' ', min_class, ' has the least images= ', min_value)\n",
    "# lets get the average height and width of a sample of the train images\n",
    "ht=0\n",
    "wt=0\n",
    "# select 100 random samples of train_df\n",
    "train_df_sample=train_df.sample(n=100, random_state=123,axis=0)\n",
    "for i in range (len(train_df_sample)):\n",
    "    fpath=train_df_sample['filepaths'].iloc[i]\n",
    "    img=plt.imread(fpath)\n",
    "    shape=img.shape\n",
    "    ht += shape[0]\n",
    "    wt += shape[1]\n",
    "print('average height= ', ht//100, ' average width= ', wt//100, 'aspect ratio= ', ht/wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fabdaed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy 2286\n",
      "Minimal 1516\n",
      "Severe 173\n"
     ]
    }
   ],
   "source": [
    "# Drop specified classes\n",
    "\n",
    "drop_classes = [\"Healthy\",'Moderate', 'Severe' ]\n",
    "\n",
    "train_df = train_df[~train_df['labels'].isin(drop_classes)]\n",
    "valid_df = valid_df[~valid_df['labels'].isin(drop_classes)]  \n",
    "test_df = test_df[~test_df['labels'].isin(drop_classes)]\n",
    "\n",
    "# Update the list of classes \n",
    "list_of_classes = [c for c in list_of_classes if c not in drop_classes]\n",
    "\n",
    "# Re-calculate the total classes\n",
    "class_count = len(list_of_classes)\n",
    "\n",
    "# Re-count the images per class\n",
    "groups = train_df.groupby('labels')  \n",
    "for label in list_of_classes:\n",
    "    group = groups.get_group(label) \n",
    "    print(label, len(group))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fac81e",
   "metadata": {},
   "source": [
    "## now trim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec49b7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples=500\n",
    "# since each class has more than 200 images all classes will be trimmed to have 200 images per class\n",
    "min_samples=500\n",
    "column='labels'\n",
    "train_df= trim(train_df, max_samples, min_samples, column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768364f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=500 # number of samples in each class\n",
    "working_dir=r'./' # directory to store augmented images\n",
    "img_size=IMGSZ # size of augmented images\n",
    "train_df=balance(train_df, n, working_dir, img_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97aa876",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (train_df['labels'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e598bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "35b4f095",
   "metadata": {},
   "source": [
    "## pre processing and f ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb552178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\deepa\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\deepa\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "79/79 [==============================] - 362s 5s/step\n",
      "26/26 [==============================] - 114s 4s/step\n",
      "Accuracy on validation data (SVM): 0.38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Doubtful       0.22      0.25      0.24       153\n",
      "     Healthy       0.56      0.49      0.52       328\n",
      "     Minimal       0.35      0.26      0.30       212\n",
      "    Moderate       0.28      0.47      0.35       106\n",
      "      Severe       0.31      0.41      0.35        27\n",
      "\n",
      "    accuracy                           0.38       826\n",
      "   macro avg       0.34      0.37      0.35       826\n",
      "weighted avg       0.40      0.38      0.38       826\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_extract_features(df, img_size):\n",
    "    img_data = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        img = cv2.imread(row['filepaths'])\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        img_data.append(img)\n",
    "        labels.append(row['labels'])\n",
    "\n",
    "    img_data = np.array(img_data)\n",
    "    labels = np.array(labels)\n",
    "    return img_data, labels\n",
    "\n",
    "img_size = (224, 224)\n",
    "train_data, train_labels = preprocess_and_extract_features(train_df, img_size)\n",
    "valid_data, valid_labels = preprocess_and_extract_features(valid_df, img_size)\n",
    "\n",
    "\n",
    "# Load ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "model = Model(inputs=base_model.input, outputs=x)\n",
    "\n",
    "# Extract features\n",
    "train_features = model.predict(train_data)\n",
    "valid_features = model.predict(valid_data)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Train an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear', random_state=123, C=1.0)\n",
    "svm_classifier.fit(train_features, train_labels)\n",
    "\n",
    "# Predict using the trained SVM classifier\n",
    "valid_predictions_svm = svm_classifier.predict(valid_features)\n",
    "\n",
    "# Evaluate the performance of the SVM classifier\n",
    "accuracy_svm = accuracy_score(valid_labels, valid_predictions_svm)\n",
    "print(f'Accuracy on validation data (SVM): {accuracy_svm:.2f}')\n",
    "\n",
    "print(classification_report(valid_labels, valid_predictions_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0571b8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 64s 4s/step\n"
     ]
    }
   ],
   "source": [
    "def preprocess_and_extract_features1(df, img_size):\n",
    "    img_data = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        img = cv2.imread(row['filepaths'])\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        img_data.append(img)\n",
    "        labels.append(row['labels'])\n",
    "\n",
    "    img_data = np.array(img_data)\n",
    "    labels = np.array(labels)\n",
    "    return img_data, labels\n",
    "\n",
    "\n",
    "test_data1, test_labels1 = preprocess_and_extract_features1(test_df, img_size)\n",
    "test_features1 = model.predict(test_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab7148bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data: 0.42\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy on the test data\n",
    "test_predictions = svm_classifier.predict(test_features1)\n",
    "test_accuracy = accuracy_score(test_labels1, test_predictions)\n",
    "print(f'Accuracy on test data: {test_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9e277bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Doubtful       0.36      0.27      0.31       100\n",
      "     Healthy       0.36      0.53      0.43       100\n",
      "     Minimal       0.33      0.24      0.28       100\n",
      "    Moderate       0.37      0.46      0.41       100\n",
      "      Severe       0.77      0.61      0.68       100\n",
      "\n",
      "    accuracy                           0.42       500\n",
      "   macro avg       0.44      0.42      0.42       500\n",
      "weighted avg       0.44      0.42      0.42       500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[27 41 16 16  0]\n",
      " [25 53 12 10  0]\n",
      " [14 34 24 22  6]\n",
      " [ 8 18 16 46 12]\n",
      " [ 1  2  4 32 61]]\n",
      "Precision: 0.42\n",
      "Recall: 0.42\n",
      "F1 Score: 0.42\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(test_labels1, test_predictions)\n",
    "precision = precision_score(test_labels1, test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "recall = recall_score(test_labels1, test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "f1 = f1_score(test_labels1, test_predictions, average='micro')  # Choose 'micro', 'macro', 'weighted' for multiclass\n",
    "print(classification_report(test_labels1, test_predictions))\n",
    "\n",
    "# Print the results\n",
    "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
    "print(f'Precision: {precision:.2f}')\n",
    "print(f'Recall: {recall:.2f}')\n",
    "print(f'F1 Score: {f1:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96a326c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Healthy   Doubtful\n",
      "Healthy   Moderate\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Moderate\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Moderate\n",
      "Healthy   Healthy\n",
      "Healthy   Minimal\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Minimal\n",
      "Healthy   Healthy\n",
      "Healthy   Doubtful\n",
      "Healthy   Moderate\n",
      "Healthy   Doubtful\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Healthy   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Minimal\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Minimal\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Minimal\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Moderate\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Healthy\n",
      "Doubtful   Doubtful\n",
      "Doubtful   Healthy\n",
      "Doubtful   Minimal\n",
      "Doubtful   Moderate\n",
      "Doubtful   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Doubtful\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Minimal\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Severe\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Severe\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Doubtful\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Moderate\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Moderate\n",
      "Minimal   Doubtful\n",
      "Minimal   Severe\n",
      "Minimal   Healthy\n",
      "Minimal   Minimal\n",
      "Minimal   Minimal\n",
      "Minimal   Moderate\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Severe\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Minimal   Healthy\n",
      "Minimal   Doubtful\n",
      "Minimal   Severe\n",
      "Minimal   Severe\n",
      "Minimal   Minimal\n",
      "Minimal   Doubtful\n",
      "Minimal   Healthy\n",
      "Moderate   Severe\n",
      "Moderate   Minimal\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Minimal\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Healthy\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Healthy\n",
      "Moderate   Minimal\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Minimal\n",
      "Moderate   Minimal\n",
      "Moderate   Minimal\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Severe\n",
      "Moderate   Severe\n",
      "Moderate   Minimal\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Severe\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Doubtful\n",
      "Moderate   Healthy\n",
      "Moderate   Minimal\n",
      "Moderate   Doubtful\n",
      "Moderate   Severe\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Minimal\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Severe\n",
      "Moderate   Minimal\n",
      "Moderate   Moderate\n",
      "Moderate   Healthy\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Moderate\n",
      "Moderate   Minimal\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Minimal\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Minimal\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Minimal\n",
      "Severe   Healthy\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Healthy\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Moderate\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Doubtful\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Minimal\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n",
      "Severe   Severe\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(test_labels1)):\n",
    "    print(test_labels1[i],\" \", test_predictions[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8df6c8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 212ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 214ms/step\n",
      "1/1 [==============================] - 0s 199ms/step\n",
      "1/1 [==============================] - 0s 193ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "1/1 [==============================] - 0s 188ms/step\n",
      "Image 1: Actual Label: 0, Predicted Label: Healthy\n",
      "Image 2: Actual Label: 0, Predicted Label: Healthy\n",
      "Image 3: Actual Label: 0, Predicted Label: Healthy\n",
      "Image 4: Actual Label: 0, Predicted Label: Healthy\n",
      "Image 5: Actual Label: 0, Predicted Label: Healthy\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "# Define the directory paths for classes 0, 3, and 4\n",
    "class_directories = {\n",
    "    '0': r'C:\\Users\\deepa\\OneDrive\\Desktop\\major\\knee\\test\\0',\n",
    "   # '3': '/content/drive/MyDrive/Colab Notebooks/Knee_data_Clahe/test/3',\n",
    "    '4': r'C:\\Users\\deepa\\OneDrive\\Desktop\\major\\knee\\train\\4'\n",
    "}\n",
    "\n",
    "# Specify the number of random images to select\n",
    "num_random_images = 5\n",
    "\n",
    "# Initialize lists to store actual and predicted labels\n",
    "actual_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "# Select random images from the specified classes\n",
    "for label, directory in class_directories.items():\n",
    "    image_files = os.listdir(directory)\n",
    "    random_images = random.sample(image_files, num_random_images)\n",
    "    for image_file in random_images:\n",
    "        actual_labels.append(label)\n",
    "        image_path = os.path.join(directory, image_file)\n",
    "\n",
    "        # Preprocess and extract features from the image\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, img_size)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img / 255.0\n",
    "        img = np.expand_dims(img, axis=0)  # Reshape to match model input\n",
    "\n",
    "        # Use the trained Random Forest classifier to predict the label\n",
    "        predicted_label = rf_classifier.predict(model.predict(img))\n",
    "        predicted_labels.append(predicted_label[0])\n",
    "\n",
    "# Display the actual and predicted labels for each image\n",
    "for i in range(num_random_images):\n",
    "    actual_label = actual_labels[i]\n",
    "    predicted_label = predicted_labels[i]\n",
    "    print(f\"Image {i + 1}: Actual Label: {actual_label}, Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad586df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784d316c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
